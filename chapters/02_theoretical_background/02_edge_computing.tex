\section{Edge Computing}
\label{section:edge-computing}

    In this chapter, we will introduce the concept of edge computing. We will explain the general term and put edge computing into context with current trends and movements in the industry. Then we will look at reasons why edge computing is becoming increasingly popular in industrial IoT environments.
    
    \subsection{Terminology and Definition}
        The term ``edge computing'' is very broad and not precisely defined in the literature. First, the term ``edge'' needs to be clarified. While some describe it as the last hop before smart- or end devices or even include end devices like IIoT devices themselves, the Industrial Internet Consortium (IIC) defines the edge as the boundary between the pertinent digital and physical entities, delineated by IoT devices. From a high-level perspective, edge computing can now be described as the opposite of the centralized data processing pattern, since as much as possible processing gets executed directly on the edge where data is created or events of interest occur, whereas in a centralized approach, most computation happens in a remote data center \cite{simpkins_opportunities_2022}. % Opportunities and Challenges in Edge Computing under K8s
        Another commonly used definition can be found in the ``Industrial Internet Consortium (IIC) vocabulary'', which defines ``edge computing'' as a form of distributed computing in which processing takes place on a set of networked machines that are near the edge. The exact borders of edge computing are hard to identify and have to be defined by the requirements of the system in question 
        \cite{baudoin_industrial_nodate, % The Industrial Internet of Things Vocabulary
        perez_edge_2022}. % Edge computing: A grounded theory study

        An edge computing system typically consists of components like edge devices, edge servers, edge gateways and edge connectors. Edge devices act as the connection between the physical things in the field, and are mostly sensors or actuators or servers with direct connections to these. Because these are as close as it gets to the physical world, systems with strict low latency requirements will typically run on them directly. Since edge devices in the real world are often not more powerful than a microcontroller, edge servers are responsible for more computationally expensive efforts. They are responsible for gathering data from edge devices and processing it in some way. Here, workloads that have requirements regarding low latency which are less strict than the ones of applications running directly on edge devices are located. Edge gateways are placed between the edge devices and the applications that use the generated data and are responsible for the delivery of data between these edge devices and applications. This can be used to overcome network borders or protocol limitations. In many cases, an edge server can act as the edge gateway, if the according network setup etc.\ allows it. Lastly, edge connectors, which are typically just software, deal with the heterogeneous set of protocols that typically exists in edge computing. They might for example forward data from a radio protocol to a different network via TCP/IP which is essential in scenarios like device-to-cloud communication and can be incorporated in any of the other edge components \cite{atos_2021_2021}. All of the components are generally located on-premises and hence require maintenance and operational efforts for the hardware. The set of all of the mentioned components can be seen as the ``edge''.
            
    \subsection{Application of Edge Computing in IIoT}
        Within the realm of IIoT, edge computing is a rapidly emerging trend. An article by Atos predicts that by 2023 more than half of new enterprise IT infrastructure will be deployed at the edge rather than centralized data centers compared to around 10\% in 2021. According to Gartner, around 75\% of enterprise-generated data will be created and processed at the edge by 2025 \cite{atos_2021_2021}. While the actual values differ in most predictions, the trend of growth in the edge computing context is a common understanding. The application of edge computing in IIoT has a set of reasons, the most obvious being the reduction of communication latency within the system. By shortening the distance between the creation of data or events of interest and the location where the actual computation happens, response times and latencies can be significantly decreased. For production critical services like visual inspection where high latencies may result in financial damage or could even endanger humans this is essential. By having full operational control over devices and networks that are participating in communication, strong security can be achieved which is especially necessary in the context of sensitive data. Another benefit of incorporating edge computing in IIoT is the more efficient usage of available resources. Since data is preprocessed (e.g.\ aggregated or filtered), less data has to travel through the network thus using less bandwidth, less energy and also producing less cloud cost. Not only is this more energy efficient and can even be better in terms of sustainability, but can also be inevitable in large systems. IBM estimates that by 2025 each person will have at least one data interaction every 18 seconds. Many of these interactions can be traced back to the billions of IoT devices, which are expected to create over 90 zettabytes of data in the year of 2025. With that volume of data, a centralized approach is presumed to result in bandwidth, energy and latency issues making it unsustainable and even infeasible. With edge computing, the challenge of processing these massive amounts of data can be tackled. Also, requirements of an IIoT system like low cost, data sensitivity, network fault tolerance and resilience can be met, which is often impossible with the typical cloud computing paradigm
        \cite{perez_edge_2022, % Edge computing: A grounded theory study
        ibm_betting_edge_computing}.  % IBM: Why organizations are betting

    \subsection{Infrastructure for Edge Computing}
        While edge computing opens many doors for IIoT systems, it also introduces complexities and increases the burden of operational maintenance. While managing hardware is not a new task in the IT environment, there are not yet enough techniques for management at this massive scale. The high amount of devices, heterogeneity of protocols, technologies and even environments (edge, cloud, etc.) make this even more difficult. Additionally, a thorough understanding and the capability of managing security and networking is essential, particularly using concepts such as zero trust and the principle of least privilege. Because of the growing interest in edge computing the industry's need for this is closer than many expect. Infrastructure, DevOps and platform practices like scheduling and orchestration, observability, etc. are essential and must be built as soon as possible. The automation of provisioning, scaling and maintaining such systems while keeping operational costs under control is a vital element for success in modern IIoT applications \cite{perez_edge_2022, youtube_ibm_technology_what_2019}. In \autoref{chapter:infrastructure-provisioning} and \autoref{chapter:poc} suggestions for dealing with these challenges will be made by addressing them in a real-world implementation. 
