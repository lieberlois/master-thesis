\section{CI/CD and GitOps}
\label{section:architecture-gitops}
    In \autoref{section:gitops} we discovered that the GitOps framework can be very useful in large-scale platforms with an enormous set of heterogeneous delivery targets. In this section, we will look at how the reference architecture proposes to employ GitOps in a hybrid cloud IIoT system.

    Once an IIoT platform surpasses a few production sites, the amount of environments in the system increases rapidly. Classic CI/CD pipelines then quickly begin to cause issues not only in terms of scale but also in their complexity. For a large-scale IIoT platform, having a simple and scalable deployment mechanism for all Kubernetes-based targets distributed over a large set of environments is desirable. Common use cases like batch deployments to many environments at once and sharing as much configuration between deployment targets to reduce code duplication should be possible with the chosen strategy. The reference architecture suggests using the GitOps model which we already discussed in \autoref{section:gitops} by having a GitOps controller running on each environment's Kubernetes instance which is configured to watch the parts of a Git repository relevant to the according environment. The implementation of the pull model in GitOps comes with significant scalability, making it highly effective for large-scale systems since the computational power of each environment is used, rather than using central and shared computational power like in common CI/CD pipeline implementations. Eventually, the GitOps controllers will sync the desired state from Git and the actual state of the delivery targets. Through this model, the system gains additional security since information is only pulled from Git rather than being pushed from pipelines, which allows engineers to further lock down their systems since no access from outside is required for the delivery anymore. In the context of Kubernetes, this means that the Kubernetes API does not need to be exposed to the CI/CD pipeline agents but can remain only accessible to the developers, which increases security even further. The reduction of code duplication is typically achieved by using techniques like ``Helm Templates'' or configuration management and overlay tools like ``Kustomize''. These offer ways to share as much code as possible between environments while giving developers the possibility to customize the configurations per environment where needed - all based on configuration files that again can be stored in Git and pulled by GitOps controllers running within the environments. Using shared code, batch deployments can easily be made since the configuration is shared across many environments anyways \cite{building_iiot}.\newline

    To effectively implement the GitOps framework, every component of the system must be describable in a declarative format and reconcilable by some sort of controller. While this is simple for typical workload deployments, it gets more challenging for infrastructure. To address this challenge, Kubernetes-native tools such as Crossplane, Pulumi, ClusterAPI, Custom Operators and many more options can be used. These tools integrate Infrastructure-as-Code capabilities into the GitOps framework by providing custom GitOps controllers for the according configuration types. An example for this is using custom resource definitions for managing cloud provider resources such as managed databases. Domain-specific custom operators even allow to store configuration like RBAC management of applications such as databases as configuration in Git. The target of this is that everything, be it deployments, infrastructure, cloud resources and more, is stored in Git as the single source of truth in the end. To be able to store secrets in Git in an encrypted manner, tools like ``Mozilla SOPS'', ``Sealed Secrets'' or ``External Secrets Operator'' are commonly used. Depending on the project it can make sense to give all developers access to this single source of truth so that teams can manage infrastructure etc.\ through some sort of agreed upon Git workflow (pull requests, code reviews, etc.), which reduces the risk of the platform team becoming the bottleneck of the project.

    It is also essential to mention that the use of the GitOps framework which the reference architecture suggests is not a replacement for CI/CD pipelines. While GitOps controllers manage continuous delivery tasks, pipeline implementations remain responsible for integration activities such as building projects, running tests, and publishing artifacts. These pipelines generate configurations, such as Helm charts, as artifacts, which are from then on managed only by the GitOps controllers. This structure leverages the strengths of both approaches: it utilizes the continuous integration capabilities of pipelines during the development phase and employs the continuous delivery mechanisms of the GitOps framework for deployment.