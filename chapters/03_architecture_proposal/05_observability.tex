\section{System Observability}
\label{section:observability}
    This section deals with the observability of a system built upon the proposed reference architecture. At the latest when a system surpasses the Proof-of-Concept (PoC) stage and grows beyond a few environments, having a central observability system that reaches across the whole system becomes a non-negotiable requirement, especially due to the highly distributed nature of the system. The suggestion of the reference architecture to build the system based on a uniform technology, in particular Kubernetes, allows for applying a standardized strategy for observability encompassing all environments. The significance of observability extends beyond typical monitoring scenarios, as highlighted by its inclusion in the ``Open Web Application Security Project Top 10'' (OWASP Top 10), which is a standard awareness document for developers and web application security. It represents a broad consensus about the most critical security risks to web applications and includes ``Insufficient Logging \& Monitoring'' as one of the most critical ones. While the lack of observability is hardly represented in CVE (Common Vulnerabilities and Exposures) or CVSS (Common Vulnerability Scoring System) data, failures in this category directly impact visibility, incident alerting and forensics, which indicates the importance of having proper observability set up \cite{owasp_top_ten}.\newline

    \noindent In the context of observability, it is often spoken of the ``three pillars'' of observability which are metrics, logs and traces. Since this thesis focuses more on the infrastructure and less on the domain-specific applications of an IIoT system, and traces are mostly used for application development while metrics and logs give insights about infrastructural components, this work will exclude traces and leave it as further work. Note that just having metrics and logs is not enough - supporting systems and strategies have to be applied in order to fully use their potential.

    \begin{quote}
        ``Logs, metrics, and traces are useful tools that help with testing, understanding, and debugging systems. However, itâ€™s important to note that plainly having logs, metrics, and traces does not result in observable systems.'' -- Cindy Sridharan, Google \cite{need_for_observability}
    \end{quote}
    
    \noindent Let us explore how to effectively create and store metrics and logs and how they can be used efficiently in a system. Metrics are numerical representations of a value of a point in time stored as time series data. Components within the system, such as the MQTT brokers of the unified namespace (\autoref{section:unified-namespace}) can provide metrics like network throughput and messages per second, offering valuable data for other components to utilize. Domain-specific applications can be instructed to provide both predefined metrics like resource and storage usage and domain-specific metrics that depend on the use case. The metrics are typically processed in a push model, where services push their metrics into a centralized store, or a pull model, where an agent is configured to scrape (pull) metrics from all configured targets to then persist them. Compared to the other pillars of observability, metrics are cheap to store while still providing valuable information, especially for monitoring and alerting. The reference architecture suggests storing metrics of all system components in a centralized store in the cloud. Each environment will first store its own metrics in a local time series database which acts as a buffer, and will remotely write the data into the centralized store in the cloud \cite{building_iiot}. This strategy ensures that monitoring persists during network disruptions by locally buffering metrics, which are then forwarded once the network connection is reestablished, preventing the loss of data that would occur without such a buffer. Finally, a user interface in the cloud environment is used to visualize metrics of all environments in the system to enrich their value even more.

    Logs on the other hand are omnipresent in software and are of tremendous help when trying to understand a system and its behaviour. While metrics are continuously present, logs only appear occurrence-based and capture information on what and when something happens in the system. Since the sheer volume of logs can cause large amounts of storage and network usage, it is often infeasible to centralize the log aggregation of a full system which is why the reference architecture suggests only aggregating them per production site with sane retention times \cite{building_iiot}. The storage for logs is typically realized by using a search engine like OpenSearch or ElasticSearch, which are time series databases optimized for efficiently persisting (``indexing'') and querying string-based data, which fits perfectly for logs. Each machine in each environment runs an agent called a ``log shipper'', which forwards logs generated by applications running on the machine to the search engine. Using the search engine, developers can easily query the long-term storage to acquire the desired logs of any component running within the according production site. In order to maximize the value of logs, structured logging should be used which describes writing logs in a well-structured and consistent format that can be easily read, searched, and analyzed by any application or any interested individual. The most common structured logging format is using JSON \cite{sematext_structured_logging}. To enhance querying capabilities, the JSON fields should be uniform across the environments. A minimal log entry could e.g. be defined as a JSON document containing a ``timestamp'', ``message'' and ``environment'' field.\newline

    By having a centralized cloud-based store for metrics and a search engine storing logs per production site and one search engine in the cloud for logs occurring in the cloud environment, the two pillars of observability ``metrics'' and ``logs'' are sufficiently covered. \newpage
